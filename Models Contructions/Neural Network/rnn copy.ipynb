{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber\n",
    "\n",
    "original_data = pd.read_csv('../../Data/rnn_data.csv', low_memory=False)\n",
    "original_data = original_data.groupby('contractSymbol').filter(lambda x: x['Date'].nunique() == 6).sort_values(by=[\"contractSymbol\", \"Date\"])\n",
    "original_data.drop(\"Ticker\", axis=1, inplace=True)\n",
    "\n",
    "call_data = original_data[original_data[\"Call\"] == 1]\n",
    "put_data = original_data[original_data[\"Call\"] == 0]\n",
    "\n",
    "data = call_data\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data.sort_values(by='Date')\n",
    "data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "features_to_scale = ['strike', 'Underlying Price', 'Annualized Volatility', 'lastPrice', 'Expiration']\n",
    "scaler = MinMaxScaler()\n",
    "data[features_to_scale] = scaler.fit_transform(data[features_to_scale])\n",
    "\n",
    "data['Time_to_Maturity'] = (pd.to_datetime(data['Expiration']) - data['Date']).dt.days\n",
    "features_to_scale.append('Time_to_Maturity')\n",
    "\n",
    "def create_sequences(data, window_size=6):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        seq = data.iloc[i:i + window_size][features_to_scale].values\n",
    "        target = data.iloc[i + window_size]['lastPrice']\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "X, y = create_sequences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "\n",
    "RNN_call = Sequential([\n",
    "    Bidirectional(LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]))),\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu', kernel_regularizer='l2'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "RNN_call.compile(optimizer=Adam(learning_rate=1e-3), loss=Huber(), metrics=['mae', 'mape'])\n",
    "RNN_call.summary()\n",
    "\n",
    "history = RNN_call.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping, lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "loss, mae, mape = RNN_call.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss}, Test MAE: {mae}, Test MAPE: {mape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
